akka {
  loglevel = INFO
  
  actor {
    provider = cluster
    
//    serializers {
//      file = "com.callhandling.typed.persistence.FileSerializer"
//    }
//    serialization-bindings {
//      "com.callhandling.typed.persistence.FileState" = file
//      "com.callhandling.typed.persistence.UploadFile" = file
//      "com.callhandling.typed.persistence.FileCommand" = file
//      "com.callhandling.typed.persistence.UploadFileCommand" = file
//      "com.callhandling.typed.persistence.FileEvent" = file
//    }
//    serialization-identifiers {
//      "com.callhandling.typed.persistence.FileSerializer" = 100
//    }
  }

  # For the sample, just bind to loopback and do not allow access from the network
  # the port is overridden by the logic in main class
  remote.artery.canonical.port = 0
  remote.artery.canonical.hostname = 127.0.0.1
  remote.artery.enabled = on

  cluster {
    seed-nodes = [
      "akka://ClusterSystem@127.0.0.1:2551",
      "akka://ClusterSystem@127.0.0.1:2552"]

    # Only for convenience in the sample, auto-downing should not be used for actual applications.
    # Read more here: http://doc.akka.io/docs/akka/current/scala/cluster-usage.html#auto-downing-do-not-use-
    auto-down-unreachable-after = 10s

    # Needed when running many actor systems in the same JVM
    jmx.multi-mbeans-in-same-jvm = on
  }

  # use Cassandra to store both snapshots and the events of the persistent actors
  persistence {
    journal.plugin = "cassandra-journal"
    snapshot-store.plugin = "cassandra-snapshot-store"
  }

}
